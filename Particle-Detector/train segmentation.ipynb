{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I_a = preprocessing_utils.pad_for_window(I_a,\n",
    "                           chopin.receptive_field_shape[0],\n",
    "                           chopin.receptive_field_shape[1])\n",
    "\n",
    "graph = graph_utils.prims_initialize(img)\n",
    "\n",
    "ground_truth_cuts, gt_graph, gt_assignments = graph_utils.generate_gt_cuts(gt,\n",
    "                                                                           seeds,\n",
    "                                                                           assignments=True)\n",
    "\n",
    "local_loss = []\n",
    "local_accuracy = []\n",
    "\n",
    "saved_models_path = os.path.join(foldername, \"saved_models\")\n",
    "\n",
    "if os.path.exists(saved_models_path):\n",
    "    shutil.rmtree(saved_models_path)\n",
    "os.mkdir(saved_models_path)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {}\".format(epoch + 1))\n",
    "    msf = chopin.predicted_msf(I_a, graph, seeds)\n",
    "    segmentations = display_utils.assignments(np.zeros_like(img), msf, seeds)\n",
    "\n",
    "    shortest_paths = nx.get_node_attributes(msf, 'path')\n",
    "    assignments = nx.get_node_attributes(msf, 'seed')\n",
    "    cuts = graph_utils.get_cut_edges(msf)\n",
    "\n",
    "    acc = graph_utils.accuracy(assignments, gt_assignments)\n",
    "\n",
    "    print(\"Accuracy: \", acc)\n",
    "    local_accuracy.append(acc)\n",
    "\n",
    "    filename = \"epoch_{}.png\".format(epoch + 1)\n",
    "\n",
    "    boundaries = display_utils.view_boundaries(np.zeros_like(img),\n",
    "                                               cuts)\n",
    "\n",
    "    plt.imsave(os.path.join(foldername, filename), boundaries)\n",
    "\n",
    "    constrained_msf = msf.copy()\n",
    "\n",
    "    constrained_msf.remove_edges_from(ground_truth_cuts)\n",
    "\n",
    "    constrained_msf = graph_utils.minimum_spanning_forest(img, constrained_msf, seeds)\n",
    "\n",
    "    ground_truth_paths = nx.get_node_attributes(constrained_msf, 'path')\n",
    "\n",
    "    children = graph_utils.compute_root_error_edge_children(shortest_paths,\n",
    "                                                      ground_truth_paths, cuts,\n",
    "                                                      ground_truth_cuts)\n",
    "\n",
    "    weights = []\n",
    "    static_images = []\n",
    "    dynamic_images = []\n",
    "\n",
    "    for (u, v), weight in children.iteritems():\n",
    "\n",
    "        try:\n",
    "            static_images.append(msf.get_edge_data(u, v)['static_image'])\n",
    "            dynamic_images.append(msf.get_edge_data(u, v)['dynamic_image'])\n",
    "            weights.append(weight)\n",
    "            altitude_val = msf.get_edge_data(u, v)['weight']\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    batches = zip(preprocessing_utils.create_batches(np.expand_dims(np.stack(weights), 1)),\n",
    "                  preprocessing_utils.create_batches(np.stack(static_images)),\n",
    "                  preprocessing_utils.create_batches(np.stack(dynamic_images)))\n",
    "\n",
    "    loss = 0\n",
    "    with chopin.sess.as_default():\n",
    "        chopin.sess.run(chopin.zero_ops)\n",
    "\n",
    "        for w, s, d in batches:\n",
    "            feed_dict = {chopin.gradient_weights: w.transpose(),\n",
    "                         chopin.static_input: s,\n",
    "                         chopin.dynamic_input: d,\n",
    "                         keras.backend.learning_phase(): 0}\n",
    "\n",
    "            chopin.sess.run(chopin.accum_ops, feed_dict)\n",
    "            loss = chopin.sess.run(chopin.loss, feed_dict)\n",
    "            loss += loss[0][0]\n",
    "\n",
    "        chopin.sess.run(chopin.train_step)\n",
    "\n",
    "\n",
    "\n",
    "    local_loss.append(loss)\n",
    "    print(\"Loss: \", loss)\n",
    "\n",
    "    chopin.save_model(\"models/saved_model/Chopin/model.ckpt\")\n",
    "    model_name = \"epoch_{}\".format(epoch)\n",
    "    chopin.save_model(os.path.join(foldername, \"saved_models\", model_name, model_name))\n",
    "\n",
    "return segmentations, global_loss, global_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
