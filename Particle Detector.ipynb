{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handle Imports\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/collin/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:43: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/collin/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:44: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/collin/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:45: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/collin/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:46: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This module will handle pre-processing such as labeling inages as positives and negatives.\n",
    "'''\n",
    "\n",
    "#Read all images from folder\n",
    "pospath = \"/home/collin/Desktop/Positives/\"\n",
    "positives = [f for f in listdir(pospath) if isfile(join(pospath, f))]\n",
    "\n",
    "negpath = \"/home/collin/Desktop/Negatives/\"\n",
    "negatives = [f for f in listdir(negpath) if isfile(join(negpath, f))]\n",
    "\n",
    "#create array to hold all data\n",
    "numImages = len(positives) + len(negatives)\n",
    "data = np.zeros((numImages, 1025))\n",
    "\n",
    "#choose 80/20 ratio for splitting data because of Pareto principle\n",
    "split = math.floor(numImages * 0.8)\n",
    "\n",
    "#load Positives\n",
    "for i in range(len(positives)):\n",
    "    path = pospath + positives[i]\n",
    "    particle = cv2.imread(path)\n",
    "    particle = cv2.cvtColor(particle, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    particle = particle.flatten()\n",
    "    particle = np.insert(particle, 1024, 1)\n",
    "    data[i] = particle\n",
    "    \n",
    "#load Negatives\n",
    "for i in range(len(negatives)):\n",
    "    path = negpath + negatives[i]\n",
    "    particle = cv2.imread(path)\n",
    "    particle = cv2.cvtColor(particle, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    particle = particle.flatten()\n",
    "    particle = np.insert(particle, 1024, 0)\n",
    "    data[len(positives) + i] = particle\n",
    "\n",
    "#shuffle examples\n",
    "np.random.shuffle(data)\n",
    "\n",
    "#split data into training and testing sets\n",
    "X_train = data[0:split, 0:1024]\n",
    "y_train = data[0:split, 1024]\n",
    "X_test = data[split:,0:1024]\n",
    "y_test = data[split:, 1024]\n",
    "\n",
    "#reshape images to be routed to classifier\n",
    "X_train = np.reshape(X_train, (split, 32, 32))\n",
    "X_test = np.reshape(X_test, (numImages - split, 32, 32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (70, 32, 32, 1)\n",
      "70 train samples\n",
      "18 test samples\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "batch_size = 10\n",
    "nb_classes = 2\n",
    "nb_epoch = 80\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 18 samples\n",
      "Epoch 1/80\n",
      "70/70 [==============================] - 0s - loss: 0.6891 - acc: 0.5143 - val_loss: 0.7085 - val_acc: 0.4444\n",
      "Epoch 2/80\n",
      "70/70 [==============================] - 0s - loss: 0.6930 - acc: 0.5714 - val_loss: 0.7054 - val_acc: 0.4444\n",
      "Epoch 3/80\n",
      "70/70 [==============================] - 0s - loss: 0.6889 - acc: 0.5000 - val_loss: 0.7207 - val_acc: 0.4444\n",
      "Epoch 4/80\n",
      "70/70 [==============================] - 0s - loss: 0.7039 - acc: 0.5714 - val_loss: 0.7041 - val_acc: 0.4444\n",
      "Epoch 5/80\n",
      "70/70 [==============================] - 0s - loss: 0.7002 - acc: 0.5714 - val_loss: 0.6976 - val_acc: 0.4444\n",
      "Epoch 6/80\n",
      "70/70 [==============================] - 0s - loss: 0.6866 - acc: 0.5857 - val_loss: 0.7037 - val_acc: 0.4444\n",
      "Epoch 7/80\n",
      "70/70 [==============================] - 0s - loss: 0.6898 - acc: 0.5714 - val_loss: 0.7066 - val_acc: 0.4444\n",
      "Epoch 8/80\n",
      "70/70 [==============================] - 0s - loss: 0.6948 - acc: 0.5714 - val_loss: 0.6999 - val_acc: 0.4444\n",
      "Epoch 9/80\n",
      "70/70 [==============================] - 0s - loss: 0.6903 - acc: 0.5714 - val_loss: 0.7029 - val_acc: 0.4444\n",
      "Epoch 10/80\n",
      "70/70 [==============================] - 0s - loss: 0.6897 - acc: 0.5714 - val_loss: 0.7025 - val_acc: 0.4444\n",
      "Epoch 11/80\n",
      "70/70 [==============================] - 0s - loss: 0.6803 - acc: 0.5571 - val_loss: 0.7197 - val_acc: 0.4444\n",
      "Epoch 12/80\n",
      "70/70 [==============================] - 0s - loss: 0.6873 - acc: 0.5714 - val_loss: 0.7012 - val_acc: 0.4444\n",
      "Epoch 13/80\n",
      "70/70 [==============================] - 0s - loss: 0.6833 - acc: 0.5714 - val_loss: 0.7092 - val_acc: 0.4444\n",
      "Epoch 14/80\n",
      "70/70 [==============================] - 0s - loss: 0.6850 - acc: 0.5714 - val_loss: 0.7121 - val_acc: 0.4444\n",
      "Epoch 15/80\n",
      "70/70 [==============================] - 0s - loss: 0.6760 - acc: 0.5714 - val_loss: 0.7274 - val_acc: 0.4444\n",
      "Epoch 16/80\n",
      "70/70 [==============================] - 0s - loss: 0.6965 - acc: 0.5571 - val_loss: 0.7042 - val_acc: 0.4444\n",
      "Epoch 17/80\n",
      "70/70 [==============================] - 0s - loss: 0.6747 - acc: 0.5571 - val_loss: 0.7200 - val_acc: 0.4444\n",
      "Epoch 18/80\n",
      "70/70 [==============================] - 0s - loss: 0.6800 - acc: 0.5714 - val_loss: 0.7184 - val_acc: 0.4444\n",
      "Epoch 19/80\n",
      "70/70 [==============================] - 0s - loss: 0.6816 - acc: 0.5714 - val_loss: 0.7121 - val_acc: 0.4444\n",
      "Epoch 20/80\n",
      "70/70 [==============================] - 0s - loss: 0.6752 - acc: 0.5857 - val_loss: 0.7127 - val_acc: 0.4444\n",
      "Epoch 21/80\n",
      "70/70 [==============================] - 0s - loss: 0.6814 - acc: 0.5714 - val_loss: 0.7147 - val_acc: 0.4444\n",
      "Epoch 22/80\n",
      "70/70 [==============================] - 0s - loss: 0.6762 - acc: 0.5714 - val_loss: 0.7156 - val_acc: 0.4444\n",
      "Epoch 23/80\n",
      "70/70 [==============================] - 0s - loss: 0.7068 - acc: 0.5714 - val_loss: 0.6942 - val_acc: 0.4444\n",
      "Epoch 24/80\n",
      "70/70 [==============================] - 0s - loss: 0.6783 - acc: 0.5714 - val_loss: 0.6953 - val_acc: 0.4444\n",
      "Epoch 25/80\n",
      "70/70 [==============================] - 0s - loss: 0.6729 - acc: 0.5571 - val_loss: 0.6969 - val_acc: 0.4444\n",
      "Epoch 26/80\n",
      "70/70 [==============================] - 0s - loss: 0.6675 - acc: 0.5714 - val_loss: 0.7036 - val_acc: 0.4444\n",
      "Epoch 27/80\n",
      "70/70 [==============================] - 0s - loss: 0.6750 - acc: 0.5714 - val_loss: 0.7099 - val_acc: 0.4444\n",
      "Epoch 28/80\n",
      "70/70 [==============================] - 0s - loss: 0.6638 - acc: 0.5571 - val_loss: 0.6869 - val_acc: 0.4444\n",
      "Epoch 29/80\n",
      "70/70 [==============================] - 0s - loss: 0.6679 - acc: 0.5714 - val_loss: 0.6839 - val_acc: 0.4444\n",
      "Epoch 30/80\n",
      "70/70 [==============================] - 0s - loss: 0.6343 - acc: 0.5857 - val_loss: 0.6847 - val_acc: 0.4444\n",
      "Epoch 31/80\n",
      "70/70 [==============================] - 0s - loss: 0.6586 - acc: 0.5857 - val_loss: 0.6854 - val_acc: 0.4444\n",
      "Epoch 32/80\n",
      "70/70 [==============================] - 0s - loss: 0.6264 - acc: 0.5857 - val_loss: 0.6648 - val_acc: 0.4444\n",
      "Epoch 33/80\n",
      "70/70 [==============================] - 0s - loss: 0.6202 - acc: 0.6286 - val_loss: 0.7028 - val_acc: 0.4444\n",
      "Epoch 34/80\n",
      "70/70 [==============================] - 0s - loss: 0.6136 - acc: 0.6714 - val_loss: 0.6597 - val_acc: 0.4444\n",
      "Epoch 35/80\n",
      "70/70 [==============================] - 0s - loss: 0.6184 - acc: 0.7000 - val_loss: 0.6455 - val_acc: 0.4444\n",
      "Epoch 36/80\n",
      "70/70 [==============================] - 0s - loss: 0.5831 - acc: 0.6429 - val_loss: 0.5992 - val_acc: 0.7778\n",
      "Epoch 37/80\n",
      "70/70 [==============================] - 0s - loss: 0.5564 - acc: 0.6143 - val_loss: 0.5736 - val_acc: 0.9444\n",
      "Epoch 38/80\n",
      "70/70 [==============================] - 0s - loss: 0.5517 - acc: 0.7429 - val_loss: 0.5933 - val_acc: 0.4444\n",
      "Epoch 39/80\n",
      "70/70 [==============================] - 0s - loss: 0.4969 - acc: 0.7857 - val_loss: 0.5287 - val_acc: 1.0000\n",
      "Epoch 40/80\n",
      "70/70 [==============================] - 0s - loss: 0.4897 - acc: 0.7286 - val_loss: 0.4605 - val_acc: 0.9444\n",
      "Epoch 41/80\n",
      "70/70 [==============================] - 0s - loss: 0.5165 - acc: 0.7571 - val_loss: 0.4787 - val_acc: 0.7778\n",
      "Epoch 42/80\n",
      "70/70 [==============================] - 0s - loss: 0.4453 - acc: 0.7857 - val_loss: 0.5544 - val_acc: 0.9444\n",
      "Epoch 43/80\n",
      "70/70 [==============================] - 0s - loss: 0.4149 - acc: 0.8714 - val_loss: 0.3612 - val_acc: 0.9444\n",
      "Epoch 44/80\n",
      "70/70 [==============================] - 0s - loss: 0.3992 - acc: 0.7714 - val_loss: 0.3598 - val_acc: 1.0000\n",
      "Epoch 45/80\n",
      "70/70 [==============================] - 0s - loss: 0.3884 - acc: 0.8857 - val_loss: 0.5310 - val_acc: 0.4444\n",
      "Epoch 46/80\n",
      "70/70 [==============================] - 0s - loss: 0.4019 - acc: 0.8571 - val_loss: 0.4358 - val_acc: 0.9444\n",
      "Epoch 47/80\n",
      "70/70 [==============================] - 0s - loss: 0.3958 - acc: 0.9000 - val_loss: 0.3731 - val_acc: 0.8889\n",
      "Epoch 48/80\n",
      "70/70 [==============================] - 0s - loss: 0.3418 - acc: 0.8857 - val_loss: 0.3584 - val_acc: 1.0000\n",
      "Epoch 49/80\n",
      "70/70 [==============================] - 0s - loss: 0.3493 - acc: 0.9000 - val_loss: 0.2481 - val_acc: 1.0000\n",
      "Epoch 50/80\n",
      "70/70 [==============================] - 0s - loss: 0.2590 - acc: 0.9714 - val_loss: 0.1931 - val_acc: 1.0000\n",
      "Epoch 51/80\n",
      "70/70 [==============================] - 0s - loss: 0.2544 - acc: 0.9286 - val_loss: 0.2923 - val_acc: 1.0000\n",
      "Epoch 52/80\n",
      "70/70 [==============================] - 0s - loss: 0.2541 - acc: 0.9571 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 53/80\n",
      "70/70 [==============================] - 0s - loss: 0.2420 - acc: 0.9000 - val_loss: 0.2101 - val_acc: 1.0000\n",
      "Epoch 54/80\n",
      "70/70 [==============================] - 0s - loss: 0.1907 - acc: 0.9286 - val_loss: 0.1549 - val_acc: 1.0000\n",
      "Epoch 55/80\n",
      "70/70 [==============================] - 0s - loss: 0.2473 - acc: 0.9000 - val_loss: 0.2574 - val_acc: 1.0000\n",
      "Epoch 56/80\n",
      "70/70 [==============================] - 0s - loss: 0.2019 - acc: 0.9286 - val_loss: 0.1755 - val_acc: 1.0000\n",
      "Epoch 57/80\n",
      "70/70 [==============================] - 0s - loss: 0.1850 - acc: 0.9714 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 58/80\n",
      "70/70 [==============================] - 0s - loss: 0.1601 - acc: 0.9714 - val_loss: 0.1505 - val_acc: 1.0000\n",
      "Epoch 59/80\n",
      "70/70 [==============================] - 0s - loss: 0.1100 - acc: 0.9857 - val_loss: 0.1252 - val_acc: 1.0000\n",
      "Epoch 60/80\n",
      "70/70 [==============================] - 0s - loss: 0.1749 - acc: 0.9714 - val_loss: 0.1355 - val_acc: 1.0000\n",
      "Epoch 61/80\n",
      "70/70 [==============================] - 0s - loss: 0.1343 - acc: 0.9571 - val_loss: 0.0846 - val_acc: 1.0000\n",
      "Epoch 62/80\n",
      "70/70 [==============================] - 0s - loss: 0.1632 - acc: 0.9429 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 63/80\n",
      "70/70 [==============================] - 0s - loss: 0.1567 - acc: 0.9857 - val_loss: 0.1444 - val_acc: 1.0000\n",
      "Epoch 64/80\n",
      "70/70 [==============================] - 0s - loss: 0.1404 - acc: 0.9714 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 65/80\n",
      "70/70 [==============================] - 0s - loss: 0.1104 - acc: 0.9857 - val_loss: 0.0749 - val_acc: 1.0000\n",
      "Epoch 66/80\n",
      "70/70 [==============================] - 0s - loss: 0.1228 - acc: 0.9571 - val_loss: 0.0989 - val_acc: 1.0000\n",
      "Epoch 67/80\n",
      "70/70 [==============================] - 0s - loss: 0.1442 - acc: 0.9714 - val_loss: 0.1035 - val_acc: 1.0000\n",
      "Epoch 68/80\n",
      "70/70 [==============================] - 0s - loss: 0.0916 - acc: 0.9857 - val_loss: 0.0635 - val_acc: 1.0000\n",
      "Epoch 69/80\n",
      "70/70 [==============================] - 0s - loss: 0.1068 - acc: 0.9857 - val_loss: 0.1212 - val_acc: 1.0000\n",
      "Epoch 70/80\n",
      "70/70 [==============================] - 0s - loss: 0.1353 - acc: 0.9714 - val_loss: 0.0682 - val_acc: 1.0000\n",
      "Epoch 71/80\n",
      "70/70 [==============================] - 0s - loss: 0.0872 - acc: 0.9857 - val_loss: 0.1358 - val_acc: 1.0000\n",
      "Epoch 72/80\n",
      "70/70 [==============================] - 0s - loss: 0.0952 - acc: 0.9857 - val_loss: 0.0636 - val_acc: 1.0000\n",
      "Epoch 73/80\n",
      "70/70 [==============================] - 0s - loss: 0.0829 - acc: 0.9714 - val_loss: 0.0690 - val_acc: 1.0000\n",
      "Epoch 74/80\n",
      "70/70 [==============================] - 0s - loss: 0.0730 - acc: 0.9714 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 75/80\n",
      "70/70 [==============================] - 0s - loss: 0.0684 - acc: 1.0000 - val_loss: 0.0708 - val_acc: 1.0000\n",
      "Epoch 76/80\n",
      "70/70 [==============================] - 0s - loss: 0.0686 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 77/80\n",
      "70/70 [==============================] - 0s - loss: 0.0586 - acc: 0.9857 - val_loss: 0.0377 - val_acc: 1.0000\n",
      "Epoch 78/80\n",
      "70/70 [==============================] - 0s - loss: 0.0706 - acc: 0.9857 - val_loss: 0.0342 - val_acc: 1.0000\n",
      "Epoch 79/80\n",
      "70/70 [==============================] - 0s - loss: 0.0705 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 1.0000\n",
      "Epoch 80/80\n",
      "70/70 [==============================] - 0s - loss: 0.0803 - acc: 0.9571 - val_loss: 0.0707 - val_acc: 1.0000\n",
      "Test score: 0.0707440376282\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=1)\n",
    "\n",
    "predictions = model.predict_classes(X_test, batch_size=32, verbose=0)\n",
    "\n",
    "displays = 8\n",
    "\n",
    "for i in range(displays):\n",
    "    x = random.sample(xrange(1,len(X_test)), displays)\n",
    "    img = np.squeeze(X_test[x[0]])\n",
    "    ax = plt.subplot(341 + i)\n",
    "    if(predictions[x[0]] == 1):\n",
    "        ax.set_title(\"Particle\")\n",
    "    else:\n",
    "        ax.set_title(\"Not a Particle\")\n",
    "    plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
